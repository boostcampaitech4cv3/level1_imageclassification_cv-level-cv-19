{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "about-heavy",
   "metadata": {},
   "source": [
    "## Libarary 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cubic-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "from importlib import import_module\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "from dataset import TestDataset, MaskBaseDataset\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "from importlib import import_module\n",
    "from torchvision.transforms import RandomAdjustSharpness, Resize, ToTensor, Normalize, Compose, CenterCrop, ColorJitter, RandomHorizontalFlip, RandomRotation, RandomAffine, RandomGrayscale, Grayscale\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4375270",
   "metadata": {},
   "source": [
    "## 모델 경로 및 모델 구조를 불러옵니다.\n",
    "\n",
    "모델경로와 모델 구조의 순서에 유의하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e256c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 파일경로를 리스트에 넣어줍니다.\n",
    "model_paths = [\n",
    "#               '/opt/ml/workspace/teajun/level1_imageclassification_cv-level-cv-19/final_ensemble_models/swinshallow_0.004_5best_f1 0.5_ 1.0.pth',\n",
    "#                 '/opt/ml/workspace/teajun/level1_imageclassification_cv-level-cv-19/final_ensemble_models/8_best_f1_0.49_0.986.pth',\n",
    "#                '/opt/ml/workspace/teajun/level1_imageclassification_cv-level-cv-19/final_ensemble_models/final_melting.pth',\n",
    "               '/opt/ml/workspace/teajun/level1_imageclassification_cv-level-cv-19/final_ensemble_models/swinbshallow_5.pth',\n",
    "#                '/opt/ml/workspace/teajun/level1_imageclassification_cv-level-cv-19/final_ensemble_models/convtiny_f1_0.838_0.827_submit.pth',\n",
    "              '/opt/ml/workspace/teajun/level1_imageclassification_cv-level-cv-19/final_ensemble_models/CV_19_EFficientNet_V2_0.04_4_best_f1_0.724_0.804_ensemble.pth'\n",
    "]\n",
    "# 모델의 클래스 구조를 넣어줍니다.\n",
    "model_structs = [\n",
    "#                  'Swin_s_Shallow', \n",
    "#                 'ConvNext_Small_Shallow',\n",
    "#                  'ConvNext_Small', \n",
    "                 'Swin_b_Shallow',\n",
    "#                  'ConvNext_Tiny',\n",
    "                 'EfficientNet_V2_L_shallow'\n",
    "                ]\n",
    "# soft voting을 사용할 경우 같은 숫자를 넣어주세요.\n",
    "# weighted voting을 사용할 경우 해당 모델에 부여할 weight를 순서대로 넣어주세요\n",
    "# 앙상블에 사용할 모델의 개수와 weights 리스트의 길이는 같아야합니다.\n",
    "weights = [1, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143ce442",
   "metadata": {},
   "source": [
    "## 데이터를 가져와 data preparation\n",
    "\n",
    "data loader를 이용해 모델에 데이터를 feeding할 준비를 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879b5f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "num_classes = MaskBaseDataset.num_classes  # 18\n",
    "data_dir = '/opt/ml/input/data/eval' # test 데이터셋의 경로를 입력하세요.\n",
    "img_root = os.path.join(data_dir, 'images')\n",
    "info_path = os.path.join(data_dir, 'info.csv')\n",
    "info = pd.read_csv(info_path)\n",
    "img_paths = [os.path.join(img_root, img_id) for img_id in info.ImageID]\n",
    "batch_size = 64\n",
    "resize=(256, 192)\n",
    "dataset = TestDataset(img_paths, resize)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=multiprocessing.cpu_count() // 2,\n",
    "    shuffle=False,\n",
    "    pin_memory=use_cuda,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "img_paths = [os.path.join(img_root, img_id) for img_id in info.ImageID]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41c367a",
   "metadata": {},
   "source": [
    "## soft voting을 구현합니다.\n",
    "\n",
    "참고: https://dhpark1212.tistory.com/entry/%EB%AA%A8%EB%8D%B8-%EC%95%99%EC%83%81%EB%B8%94ensemble-%ED%95%98%EA%B8%B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23356ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_array_3d = []\n",
    "i = 0\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "for index, (model_struct, model_path) in enumerate(zip(model_structs, model_paths)):\n",
    "\n",
    "    # 모델 생성 및 파라미터 주입\n",
    "    model_cls = getattr(import_module('model'), model_struct)\n",
    "    model = model_cls(num_classes)\n",
    "    model.load_state_dict(torch.load(model_path), model_struct)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        temp_prediction = []\n",
    "        for idx, images in enumerate(loader):\n",
    "            images = images.to(device)\n",
    "            pred = softmax(model(images))\n",
    "            temp_prediction.extend(pred.cpu().numpy())\n",
    "        prediction_array_3d.append(np.array(temp_prediction) * weights[i])\n",
    "    i += 1\n",
    "prediction_array_3d = np.array(prediction_array_3d)\n",
    "prediction = prediction_array_3d.sum(axis=0)\n",
    "prediction = prediction.argmax(axis=1)\n",
    "info['ans'] = prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f6c4c7",
   "metadata": {},
   "source": [
    "### 경로를 지정하여 CSV 파일로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ba5284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# info.to_csv('ensemble_result1.csv')\n",
    "# info.to_csv('ensemble_result2.csv')\n",
    "# info.to_csv('ensemble_result3.csv') \n",
    "# info.to_csv('ensemble_result4.csv') \n",
    "# info.to_csv('ensemble_result5.csv') \n",
    "info.to_csv('ensemble_result6.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253f5a7c",
   "metadata": {},
   "source": [
    "## Validation Acc, F1 Score\n",
    "\n",
    "validation dataset의 acc와 f1 score를 구합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea9aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir  = '/opt/ml/input/data/train/images' # 데이터의 경로를 입력하세요\n",
    "dataset_module = getattr(import_module(\"dataset\"), \"MaskSplitByProfileDatasetByClass\") #\n",
    "\n",
    "dataset_val = dataset_module(\n",
    "        data_dir=data_dir,\n",
    "    )\n",
    "dataset_val.set_transform(Compose([\n",
    "            CenterCrop((320, 256)),\n",
    "            Resize((256, 192), Image.BILINEAR),\n",
    "            ToTensor(),\n",
    "            Normalize(mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246)),\n",
    "        ]))\n",
    "_, val_set = dataset_val.split_dataset()\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=1000,\n",
    "    num_workers=multiprocessing.cpu_count() // 2,\n",
    "    shuffle=False,\n",
    "    pin_memory=use_cuda,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "prediction_array_3d = []\n",
    "for model_struct, model_path in zip(model_structs, model_paths):\n",
    "    model_cls = getattr(import_module('model'), model_struct)\n",
    "    model = model_cls(num_classes)\n",
    "    # 모델 생성 및 파라미터 주입\n",
    "    model.load_state_dict(torch.load(model_path), model_struct)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    temp_prediction = []\n",
    "    with torch.no_grad():\n",
    "        batch_prediction = []\n",
    "        for images, _ in val_loader:\n",
    "            images = images.to(device)\n",
    "            pred = softmax(model(images))\n",
    "            batch_prediction.extend(pred.cpu().numpy())\n",
    "        temp_prediction.extend(batch_prediction)\n",
    "    prediction_array_3d.append(temp_prediction)\n",
    "prediction_array_3d = np.array(prediction_array_3d)\n",
    "prediction = prediction_array_3d.sum(axis=0)\n",
    "prediction = prediction.argmax(axis=1)\n",
    "labels = np.array(dataset_val.get_multi_labels_val())\n",
    "\n",
    "acc_item = (labels == prediction).sum().item()\n",
    "print(acc_item)\n",
    "f1 = MulticlassF1Score(num_classes=18)\n",
    "\n",
    "f1_score = f1(torch.Tensor(prediction).type(torch.LongTensor), torch.Tensor(labels).type(torch.LongTensor)).item()\n",
    "\n",
    "val_acc = np.sum(acc_item) / len(val_set)\n",
    "        \n",
    "        \n",
    "print(f1_score)\n",
    "\n",
    "print(val_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
